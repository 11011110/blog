---
layout: post
title: Fast tracks for the theoretical CS conference-to-journal pipeline?
date: 2023-07-27 15:56
---
I recently received an email from Uri Feige and Mohammad T. Hajiaghayi promising a "fast-track" process "which decides submissions within 90 days of the submission date" for submissions to _Algorithmica_ of papers previously accepted to ICALP. My initial reaction was negative, but maybe I'm missing something.

For context, theoretical computer science papers are typically published first in a preliminary form in peer-reviewed conferences. These conferences can be highly selective, and their reviews can find mistakes and request corrections, but they are primarily focused on whether the work is important and superficially appears correct. They do not provide the same level of rigor that one would expect from a journal review, and there is usually only one round of review, without any opportunity for checking whether revisions addressed reviewers' concerns. The high workload expected of conference reviewers means that it might be reasonable to put in an hour of time on reviewing a paper, but not the day or days that it might take to do a journal-level review. After a paper has appeared in a conference, it is common (although not universal) for an expanded and more polished version to be sent to a journal, where it undergoes the normal journal review process. When a paper has both a conference and a journal version, the journal version is the final form of the paper, the version that can be trusted.

To me having a fast-track decision process raises all sorts of red flags. One cannot expect conference acceptance to mean that the paper has already been thoroughly reviewed at the level of rigor that would be expected for journal publication. And a 90 day deadline for a full decision is too fast to expect anything more from the reviewers than the same superficial checks, with no time for significant revisions and re-review if required. ICALP is a top-level conference (behind only STOC and FOCS in reputation) so one can expect all its papers to be significant enough for acceptance, but that doesn't make them free of oversights or mistakes (repairable or otherwise). Further, what details are provided are not reassuring. The fast-track process entails uploading one's conference reviews along with the journal submission. Does this mean that they are not even expecting to get another round of review done, but instead will rely on the single round of reviewing that the papers already had?

I previously thought of _Algorithmica_ as respectable algorithms journal, not as selective as _SIAM J. Comput._ but still good, one that wouldn't need to stoop to such stunts. I've published in it as recently as this year. I'm worried that this sort of thing comes from pressure from the publisher (Springer) to boost acceptances now that most papers in the journal are associated with significant open-access publication fees.  Encouraging theory conference authors to make journal versions of their papers is a good thing, but not if the process destroys the value of making a journal version. If that value comes from the extra level of trust one can put in the journal version of a paper, what value is being provided here?

On the other hand, maybe I'm being overly cynical. Maybe the _Algorithmica_ editors have reviewers lined up, willing to give thorough journal-quality reviews within a short timeframe. Maybe "decides submissions" allows for decisions that the submission needs at least one more full round of revision and review before a more final decision can be made. Maybe the conference reviews to be submitted with fast-track papers are there only to provide context, and not as a substitute for new journal reviews. Maybe the authors will be motivated to put in significant revisions and improvements themselves, without having to be told to do it by reviewers, so that the fast-track process ends up publishing versions of papers with significant value added without requiring a heavyweight reviewing process. Maybe. Until we see the results from this experiment, it will be difficult to tell.